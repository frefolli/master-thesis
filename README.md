# Unconventional reinforcement learning on traffic lights with SUMO

## Thesis or Master Degree in Computer Science, academic year 2024/2025

## Index

- [ ] Introduction
- [x] Traffic Science
  - [x] Introduction
  - [x] Transit regulation
  - [x] Demand models
  - [x] Settings and assumptions
- [x] Traffic Simulation
  - [x] SUMO
  - [x] Multi agent transit simulations
  - [x] SUMO-RL
- [ ] Background on Reinforcement Learning
  - [x] A new perspective
    - [x] Learning by example
    - [x] Learning by inference
    - [x] Learning by experience
  - [x] Mathematics foundation of Environment Modeling and Reinforcement Learning
    - [x] Markov Chains
    - [x] Markov Decision Processes
    - [x] Policies
    - [x] Value Functions
      - [x] State-value function
      - [x] Action-value function
      - [x] Usefulness of value functions
  - [ ] Learning to learn
    - [ ] Learning techniques
      - [x] Model-Based/Free learning
      - [x] On/Off-Policy learning
      - [x] Monte Carlo methods
      - [ ] Temporal Difference methods
    - [ ] Environment design
      - [ ] The state space
      - [ ] The action space
      - [ ] The observation function
      - [ ] The reward function
    - [ ] Experience design
      - [ ] Frankenstein learning
      - [ ] Incremental learning
      - [ ] Curriculum learning
    - [ ] Reinforcement Learning Algorithms
      - [ ] Q Learning
      - [ ] DQN
      - [ ] PPO
- [ ] Agents
  - [ ] Q Learning
  - [ ] DQN
  - [ ] PPO
  - [ ] Fixed Cycle
- [ ] Fasteners and tools
  - [ ] Observation functions
  - [ ] Reward functions
  - [ ] Traffic generation
- [ ] Experiments and findings
  - [ ] Metrics
  - [ ] 0) Picking a Reward function
  - [ ] 1) Training only on NORMAL settings
  - [ ] 2) Training with a bit of ABNORMAL settings
  - [ ] 3) Picking an Observation function
  - [ ] 4) kickstarting a self-adapting system
  - [ ] -) Impact of cycle time in fixed cycle agents
  - [ ] -) Impact of resizing quantization of states
  - [ ] -) Impact of resizing neural networks
  - [ ] -) Impact of agent expertise levels during multi-agent system training
  - [ ] -) Transfer learning between agents of same shape (modularization and idempotence)
  - [ ] -) Transfer learning between agents of different shape (mutation and adaptation)
- [ ] Threats to Validity
  - [ ] Internal threats
    - [ ] Simplistic simulation model
    - [ ] No advanced tweaks in RL Models
  - [ ] External threats
    - [ ] Tiny scenarios
    - [ ] No experimentation on wide networks with OD Matrix
- [ ] Future Work
  - [ ] Apply results to Via Bassini to lower waiting time for ATM trolleybus 93, my beloved
  - [ ] Apply results to Via Porto Corsini to catch ATM M1 in time for Bisceglie instead of Rho Fieramilano
- [ ] Conclusion
