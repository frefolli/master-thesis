\chapter{Experiments and findings}

\section{RQ 0 - Acquiring a baseline}
  \subsection{E0: Find Best Reward Function}
  \subsection{E1: Find Best Observation Function}

\section{RQ 1 - Curriculum vs Monolithic Learning}
  \subsection{E2: Find The Best Dataset}

\section{RQ 2 - Deep vs Tabular Learning}
  \subsection{E3A: Find The Best Tabular Agent}
  \subsection{E3B: Find The Best Deep Agent}

\section{RQ 3 - RL vs Fixed vs Priority}
  \subsection{E3C: Find The Best Fixed Agent}
  \subsection{E7: Try Unattended}

\section{RQ 4 - Determinism Sensitivity}
  \subsection{E11: Explore determinism (DQL)}
  \subsection{E12: Explore determinism (PPO)}

\section{RQ 5 - Quantization Sensitivity}
  \subsection{E8: Try Unquantized (DQL)}
  \subsection{E9: Try Unquantized (PPO)}

\section{RQ 6 - Multi-Agent vs Single-Agent Learning}
  \subsection{E5: Try Marl On Observation}
  \subsection{E6: Try Marl On Reward}
  \subsection{E10: Try Partition}

\section{RQ 7 - Static vs Self-Adaptive System}
  \subsection{E4: Try Self Adaptive}
