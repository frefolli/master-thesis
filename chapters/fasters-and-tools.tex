\chapter{Fasteners and Tools}

This chapter showcases and explains the architecture of the extended reinforcement learning framework \textit{SUMO-RL}, along with its components, tools and algorithms.

\section{The Core}

This section is concerned with the core of the reinforcement learning framework, containing software for implementing agents, functions and other enabling components.

\subsection{The Architecture}

SUMO-RL has a \textbf{modular} architecture (it can be seen in figure \ref{fig:sumo-rl-architecture}) that allows developers and researchers to replace a-la-carte almost all its components if needed.

The \textit{Environment} object get created through settings supplied by both command line arguments and a configuration file.
These settings select which functions, agents, scenario to use in the simulation, as well as feature flags for tuning SUMO and changing other aspects of the experiments.
The Environment is then equipped with an \textit{ObservationFunction}, a \textit{RewardFunction}, a dataframe for collecting \textit{Metrics} about agents and the simulations, an object for caching data about vehicles, lanes and intersections called \textit{Datastore}, and a dictionary of \textit{TrafficSignal}s.
Each \textit{TrafficSignal} instance represents a controlled intersection in the scenario that has been loaded in the \textit{Environment}. Upon creation, it queries SUMO to extract valuable data about the shape of the intersection and the traffic light program logic (that is to say \textit{the clock cycle and its phases}). It identifies its \textit{green phases} and represents the act of switching to one of those as an action of the Action Space.

Along with the environment, also a set of \textit{Agent}s are created which can observe the state of the simulation through the output of the \textit{ObservationFunction} and get rewarded with the output of the \textit{RewardFunction}, both of which are mediated by the \textit{Environment}.

In most of the literature works either the is only one intersection in the scenario or each agent instance is controlled strictly one of the intersections. As such, also the original SUMO-RL framework \cite{sumorl} developed by Lucas Alegre supported an agent to control only one traffic light intersection.
The architecture has been revised to allow agents to control more than one intersection by modifying both the agent trait and how the environment works.
In particular, SUMO-RL has been equipped with an algorithm for partitioning the set of controllable traffic lights intersections on the basis of the number of input lanes or the State Space shape.
By default, it assigns an distinct instance of agent to each one of the intersections in the network. If needed, it will group intersections based on the aforementioned similarities and assign a single agent instance for each group.
Furthermore, while the architecture allows for different agent types to act in the simulation at the same time, the system is actually instructed to use only one agent type at a time, because the goals of this research don't require to analyze the behaviour of different agent types on the same network.

\putimage{figures/sumo-rl-architecture.png}{The SUMO-RL Architecture}{fig:sumo-rl-architecture}{1.0}

\subsection{The Environment}

%% TODO: inserire citazione a Gymnasium

\paragraph{Loading the scenario}

The Environment component, upon creation, starts a connection with SUMO loading the scenario that has been selected. Then, it queries SUMO for IDs of traffic lights and creates and instance of TrafficSignal for each one of them passing their ID and a copy of the connection with SUMO.
The TrafficSignal constructor also accepts parameters for changing the minimum green-light duration, the maximum green-light duration and the yellow-light duration.
This way, the TrafficSignal component is able to query SUMO for its shape and traffic light control program.
Therefore it acquires the list of incoming lanes, the list of output lanes and it caches the lengths of its lanes (which will be used afterwards in computations).
It also sets its \textit{Action Space} with a \textit{gymnasium}'s Discrete space which is parametrized on the number of green phases.
The action on a traffic light is the green phase it should enable, then its up to the TrafficSignal component to enforce that phases by using the correct yellow-light transition and the correct phase in the simulations.

\paragraph{Acquiring traffic light phases}

A TrafficSignal doesn't use the program hard-coded in the SUMO scenario but construct an appropriate program analyzing the hard-coded one.
It starts fetching all phases and filling an array \textit{green-phases} with all the phases which contain at least on of green-light encoding characters (\textit{"gG"}).
The green-phases are added also to the list of output \textit{phases}.
Then, it iterates on couples of sequential green phases to build the yellow phases which are a transition from a green phases $A$ and a green phase $B$. It essentially copies the phase of $A$ replacing all occurrences of green-light characters with the yellow-light character (\textit{"y"}).
It also keep a map \textit{yellow-dict} of transitions which can be indexed by a tuple of indices ($<i, j>$) and returns the corresponding yellow phase index.

\paragraph{Running the simulation}

Before running each simulation the environment should be reset through the \textit{reset()} method.
Every time it is reset, it reloads SUMO with the previously selected scenario, the selected routes file and the input seed (important for ensuring that a performed simulation is replicable).
At each iteration of a simulation, the agents are fed with the observations granted from the Environment and their actions are collected and fed in the Environment with its \textit{step()} method.
Afterwards, some other methods can be called depending of what data is needed. At least \textit{gather\_data\_from\_sumo()} and {compute\_observations()} are needed for running a simulation but using also \textit{compute\_rewards()} allows agents to learn and the researcher to investigate results.

\begin{itemize}
  \item the \textit{gather\_data\_from\_sumo()} method essentially queries SUMO for data concerning vehicles and lanes. For each vehicle the following metrics are extracted:
  \begin{itemize}
    \item \textit{awt}: Accumulated Waiting Time is the amount of time of the last $1000$ seconds that a vehicle has spent being at full-stop.
  \end{itemize}
  For each lane, the following data are extracted:
  \begin{itemize}
      \item \textit{lsvn}: LastStepVehicleNumber is the number of vehicles present in the lane in the last step of the simulation.
      \item \textit{lshn}: LastStepHaltingNumber is the number of full-stop vehicles in the lane in the last step of the simulation.
      \item \textit{lsms}: LastSteoMeanSpeed is the average speed of vehicles in the lane in the last step of the simulation.
      \item \textit{lso}: LastStepOccupancy is the occupancy level in the lane in the last step of the simulation.
      \item \textit{lswt}: LastStepWaitingTime is the average waiting time of vehicles in the lane in the last step of the simulation.
      \item \textit{vehs}: LastStepVehicleIDs is the list of vehicles present in the lane in the last step of the simulation.
      \item \textit{mawt}: the MeanAccumulatedWaitingTime is computed by averaging accumulated waiting times of vehicles in a lane.
      \item \textit{tawt}: the TotalAccumulatedWaitingTime is computed by summing accumulated waiting times of vehicles in a lane.
  \end{itemize}
  \item the \textit{compute\_observations()} method construct observations for each traffic light with the selected ObservationFunction and stores them inside an Environment field.
  \item the \textit{compute\_rewards()} method constructs the rewards using the selected RewardFunction and stores them inside an Environment field.
  \item the \textit{compute\_metrics()} method computes the following metrics:
  \begin{itemize}
    \item \textit{step}: the current simulation step
    \item \textit{total\_running}: the number of vehicles which speed is not zero.
    \item \textit{total\_backlogged}: the number of vehicles which are enqueued and waiting to enter the simulation.
    \item \textit{total\_stopped}: the number of vehicles at full-stop.
    \item \textit{total\_arrived}: the number of vehicles which have arrived at their destination in the last step.
    \item \textit{total\_departed}: the number of vehicles which have departed in the last step (this is the same as \textit{entering the simulation}).
    \item \textit{total\_waiting\_time}: the sum of waiting time of all lanes.
    \item \textit{mean\_waiting\_time}: the mean of waiting time of all lanes.
    \item \textit{total\_accumulated\_waiting\_time}: the sum of accumulated waiting time of all lanes.
    \item \textit{mean\_accumulated\_waiting\_time}: the mean of accumulated waiting time of all lanes.
    \item \textit{mean\_speed}: the average of speed of all lanes.
    \item \textit{total\_reward}: the total of rewards released by the environment in the last step.
  \end{itemize}
  These are written to CSV files and can be analyzed to compute the performance of models as well as evaluating their fairness with respect of directions. This last option is available by setting to True a parameter called \textit{advanced\_metrics} which enables tracking the aforementioned metrics for each direction of the network (each pair of origin-destination inside the network).
\end{itemize}

\subsection{The Observation Functions}

The ObservationFunction class declares a trait (shown in Figure \ref{fig:observation-function-trait}) for a functor object which uses data from the \textit{Datastore} and the \textit{TrafficSignal}.
It supports quantization of continuous values to a configurable number of fixed levels. This operation is performed in conformity with equation \ref{eq:quantization}. By default, the number of levels is $16$, but this value can be changed by command line as needed and if it's set to zero, then no quantization is performed (this is useful for testing models with continuous spaces).
The State Space is defined by a $gymnasyum$'s Box of floating point values in range $[0, 1]$ of length \textit{observation\_space\_size()}.

\putimage{figures/observation-function-trait.png}{The ObservationFunction class/trait}{fig:observation-function-trait}{0.75}

In Table \ref{tbl:observation-features} the features which can be extracted for composing the observation of an agent are listed and detailed.
Moreover, a \textit{shared-view} mechanism has been implemented so that a traffic light agent can see not only its state through a observation function (called "me-function") but also a view over its neighbour traffic lights through a second observation function (called "you-function").
The shared-view is implemented with a cache so that the observation of a traffic light isn't computed two or more times for each time step.
Each agent has a owned observation and if the shared-view is active, then it imports in the resulting observation also the owned observation of neighbour agents.

It was chosen not to include output lane information in the observable features in order to keep the state space small. Literature works on the same topic usually keep this convention and adopts similar state features \cite{wei2019presslight} \cite{han2023leveraging}. The novelty is the inclusion of neighbour data, which also makes up for the lack of output lane data since a output lane of a intersection A can be an input lane of a neighbour intersection B.

In Table \ref{tbl:observation-functions} the available configurations for observation functions are listed by what features they allow the agent to see and if they are \textit{shared-views}. The output State Space shape is also displayed assuming that a traffic light agent has $N$ phases, $M$ incoming lanes and $K$ neighbours.
The reason behind the choice of using the Density ("d") observation function as base for the shared-views will be more clear in the next chapter.

\begin{table}[H]
  \captionof{table}{Summary of implemented observation features}
  \label{tbl:observation-features}
  \resizebox{\linewidth}{!}{
    \begin{tabular}{|l|l|l|c|}
      \hline
      Name & ID & Description & Formula \\
      \hline
      Current Phase Encoding     & \textbf{CPE} & \makecell[l]{the current traffic light phase ($CP$) encoded as one-hot vector.} &
      \makecell{$
        CPE = \left<
          \left\{
          \begin{array}{cl}
            1 & CP = P_i \\
            0 & CP \ne P_i
          \end{array}
          \right\}
          | \; \forall i \in [0, N)
        \right>
      $} \\
      \hline
      Minumum Green Time Reached & \textbf{MGR} & \makecell[l]{a boolean value which is $1$ if and only if the time since \\
                                                               when the traffic light completed a phase change ($TSLC$) has surpassed \\
                                                               the environment configured minimum green time ($MGT$).} &
      \makecell{$
        MGR = \left\{
          \begin{array}{cl}
            1 & TSLC > MGT \\
            0 & TSLC \leq MGT
          \end{array}
        \right\}
      $} \\
      \hline
      Lane Speed Percentage      & \textbf{LSP} & \makecell[l]{for each lane the average speed ($S(v)$) of vehicles in it ($V(L_i)$) is \\
                                                               divided by the maximum allowed speed on such lane ($MAS(L_i)$).} &
      \makecell{$LSP = \left< \frac {\sum _ {v \in V(L_i)} S(v)} {|V(L_i)| \; \cdot \; MAS(L_i)} \; | \; \forall i \in [0, M) \right>$} \\
      \hline
      Lane Occupancy             & \textbf{LOC} & \makecell[l]{for each lane, the percentage of its occupancy \\
                                                               is retrieved from SUMO. It is equivalent to summing \\
                                                               the lengths ($|v|$) of vehicles in a lane ($V(L_i)$) \\
                                                               divided by the length of that lane ($|L_i|$)} &
      \makecell{$LOC = \left< \frac {\sum _ {v \in V(L_i)} |v|}  {|L_i|} \; | \; \forall i \in [0, M) \right>$} \\
      \hline
      Lane Queuing Percentage    & \textbf{LQP} & \makecell[l]{for each lane, its occupancy ($LOC_i$) is multiplied by \\
                                                               the number of vehicles in such lane being at full-stop ($FSV(L_i)$) \\
                                                               and divided by the number of vehicles in that lane ($V(L_i)$).} &
      \makecell{$LQP = \left< \frac{{LOC}_i \; \cdot \; |FSV(L_i)|} {|V(L_i)|} \; | \; \forall i \in [0, M) \right>$} \\
      \hline
    \end{tabular}
  }
\end{table}

\begin{table}[H]
  \captionof{table}{Summary of implemented observation functions}
  \label{tbl:observation-functions}
  \resizebox{\linewidth}{!}{
    \begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|c|}
      \hline
      ID & \multicolumn{5}{|c|}{Itself} & \multicolumn{5}{|c|}{Neighborhood} & State Space Shape \\
      \hline
      & CPE & MGR & LSP & LOC & LQP & CPE & MGR & LSP & LOC & LQP & \\
      \hline
      default & \FilledCircle & \FilledCircle & \FilledCircle & \FilledCircle & \FilledCircle & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & ${[0,1]} ^ {log _ 2 {N} + 1 + 3 \cdot M}$ \\
      \hline
      s       & \EmptyCircle  & \EmptyCircle  & \FilledCircle & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & ${[0,1]} ^ {M}$ \\
      \hline
      d       & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \FilledCircle & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & ${[0,1]} ^ {M}$ \\
      \hline
      q       & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \FilledCircle & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & ${[0,1]} ^ {M}$ \\
      \hline
      sv      & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \FilledCircle & \EmptyCircle  & \FilledCircle & \FilledCircle & \FilledCircle & \FilledCircle & \FilledCircle & ${[0,1]} ^ {log _ 2 {N} + 1 + (3 + K) \cdot M}$ \\
      \hline
      svs     & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \FilledCircle & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \FilledCircle & \EmptyCircle  & \EmptyCircle  & ${[0,1]} ^ {(K + 1) \cdot M}$ \\
      \hline
      svp     & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \FilledCircle & \EmptyCircle  & \FilledCircle & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & ${[0,1]} ^ {(K + 1) \cdot M}$ \\
      \hline
      svd     & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \FilledCircle & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \FilledCircle & \EmptyCircle  & ${[0,1]} ^ {(K + 1) \cdot M}$ \\
      \hline
      svq     & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \FilledCircle & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \FilledCircle & ${[0,1]} ^ {(K + 1) \cdot M}$ \\
      \hline
    \end{tabular}
  }
\end{table}

\subsection{The Reward Functions}

The RewardFunction class declares a trait (shown in Figure \ref{fig:reward-function-trait}) for a functor object which uses data from the \textit{Datastore} and the \textit{TrafficSignal}.

\putimage{figures/reward-function-trait.png}{The RewardFunction class/trait}{fig:reward-function-trait}{0.75}

In Table \ref{tbl:reward-features} the features which can be extracted for composing the reward of an agent are listed and detailed.
Moreover, a \textit{shared-view} mechanism has been implemented so that a traffic light agent can be rewarded also with its neighbour rewards.
The shared-view is implemented with a cache so that the reward of a traffic light isn't computed two or more times for each time step.
Each agent has a owned reward and if the shared-view is active, then it imports in the resulting reward also the owned reward of neighbour agents.

The DWT measures how much the accumulated waiting time has decreased. If $DWT > 0$ then the accumulated waiting time is lower than before and it delivers a positive reward.

The SPD measures if vehicles are flowing at a higher speed than half the maximum allowed speed. Intuitively, if this quantity is positive, then it leads to a positive reward.

The QLE without negative sign would be non-negative number. Since its measuring the amount of halted vehicles, a negative reward is released when the absolute value of this quantity is greater then 0. This way, the agents will minimize the length of queues in controlled lanes.
Moreover, since DQL is using QLE are reference, it doesn't need to be inverted.

Finally, PRE is based on the concept of Pressure \cite{wei2019presslight}, which expresses the disequilibrium between the outcoming flow and the incoming flow.
The original formula, shown in equation \ref{eq:original-pressure}, was the difference of incoming and outcoming vehicles ($V(L_i)$) weighted by the capacity of lanes ($LC(L_i)$), which in PRE has been simplified by removing the divisions and inverting the involved quantities to deliver a positive reward whenever the outcoming flow surpasses the incoming flow.
Intuitively this means that the number of vehicles which have passed the intersection is higher than the one of queued and incoming vehicles.
More will be said in the following sections about how the capacity of a road can be calculated, but in the present research I'm assuming that all lanes have similar capacity due to the fact that the context is urban tissue which usually have $30-50$ km/h speed limits on the whole road network.

In Table \ref{tbl:reward-functions} the available configurations for reward functions are listed by what features are used and if they are \textit{shared-views}. The output Reward Space shape is also displayed assuming that a traffic light agent has $N$ incoming lanes, $M$ outcoming lanes and $K$ neighbours.
The reason behind the choice of using the DiffWaitingTime ("dwt") reward function as base for the shared-views will be more clear in the next chapter.

\begin{table}[H]
  \captionof{table}{Summary of implemented reward features}
  \label{tbl:reward-features}
  \resizebox{\linewidth}{!}{
    \begin{tabular}{|l|l|l|c|}
      \hline
      Name & ID & Description & Formula \\
      \hline
      Diff Accumulated Waiting Time  & \textbf{DWT} & \makecell[l]{the difference between the total accumulated waiting time ($TAWT$) \\
                                                                   of vehicles in its input lanes in the previous time step and the TAWT \\
                                                                   in the current time step. The DWT is divided by 100 to avoid unstable \\
                                                                   rewards due to the TAWT having an upper bound of $1000$.}
                                                    & \makecell{$ \frac {{TAWT}_{t-1} - {TAWT}_{t}} {100} $} \\
      \hline
      Average Speed                  & \textbf{SPD} & \makecell[l]{the mean of average speeds of vehicles in its input lanes $AS(L_i)$ \\
                                                                   divided by the maximum allowed speed ($MAS(L_i)$) minus $\frac {1} {2}$.}
                                                    & \makecell{$\sum _ {i \in [0, N)} \frac {AS(L_i)} {MAX(L_i)} - \frac {1} {2}$} \\
      \hline
      Queue Lengths                  & \textbf{QLE} & \makecell[l]{the mean of length of queues (as number of full-stop vehicles $FSV(L_i)$) \\
                                                                   in its input lanes multiplied by $-1$.}
                                                    & \makecell{$- \frac {\sum _ {i \in [0, N)} FSV(L_i)} {N}$} \\
      \hline
      Diff Queue Lengths             & \textbf{DQL} & \makecell[l]{the difference between the QLE in the current time step and \\
                                                                   the QLE in the previous \\ time step.} & \makecell{${QLE}_{t} - {QLE}_{t-1}$} \\
      \hline
      Pressure                       & \textbf{PRE} & \makecell[l]{for each lane, the negative pressure is defined as the difference between \\
                                                                   the number of outcoming vehicles and the number of incoming vehicles}
                                                                   & \makecell{$P = \left[ \sum _ {i \in [0, N)} V(L_i) \right] - \left[ \sum _ {i \in [0, M)} V(L_i) \right]$} \\
      \hline
    \end{tabular}
  }
\end{table}

\begin{equation} \label{eq:original-pressure}
  P =
  \left[ \sum _ {i \in [0, N)} \frac {V(L_i)} {LC(L_i)} \right]
  -
  \left[ \sum _ {i \in [0, M)} \frac {V(L_i)} {LC(L_i)} \right]
\end{equation}

\begin{table}[H]
  \captionof{table}{Summary of implemented reward functions}
  \label{tbl:reward-functions}
  \resizebox{\linewidth}{!}{
    \begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|}
      \hline
      ID & \multicolumn{5}{|c|}{Itself} & \multicolumn{5}{|c|}{Neighborhood} \\
      \hline
      & DWT & SPD & QLE & DQL & PRE & DWT & SPD & QLE & DQL & PRE \\
      \hline
      dwt   & \FilledCircle & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  \\
      \hline
      as    & \EmptyCircle  & \FilledCircle & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  \\
      \hline
      ql    & \EmptyCircle  & \EmptyCircle  & \FilledCircle & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  \\
      \hline
      dql   & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \FilledCircle & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  \\
      \hline
      p     & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \FilledCircle & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  \\
      \hline
      svdwt & \FilledCircle & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \FilledCircle & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  \\
      \hline
      svas  & \EmptyCircle  & \FilledCircle & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \FilledCircle & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  \\
      \hline
      svql  & \EmptyCircle  & \EmptyCircle  & \FilledCircle & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \FilledCircle & \EmptyCircle  & \EmptyCircle  \\
      \hline
      svdql & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \FilledCircle & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \FilledCircle & \EmptyCircle  \\
      \hline
      svp   & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \FilledCircle & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \EmptyCircle  & \FilledCircle \\
      \hline
    \end{tabular}
  }
\end{table}

\subsection{The Agents}

The Agent class declares a trait (shown in Figure \ref{fig:agent-trait}) for an object which can accepts observations, take actions, learn from errors, be serialized and deserialized. Agents only need to support at least the \textit{act()} method, the other methods are optional. For example, a fixed cycle agent won't learn nor observe the environment, it will just act.

\putimage{figures/agent-trait.png}{The Agent class/trait}{fig:agent-trait}{0.75}

Agents with various features have been implemented in order to compare the effectiveness of those approaches. Among the learning agents, there are three tabular agents and two neural network based agents. Most of them use an off-policy strategy but SARSA which is on-policy. Moreover, the two neural agents support also continuous state space and even if generally quantization will be used in experiments, an interesting point is verifying if not using quantization leads to advantages or disadvantages in performance. Furthermore, the size of neural networks is fixed to $32$ nodes per layer since an objective is to keep all the models reasonably small \footnote{If a traffic light agent needs a supercomputer sized neural network, then it's probably cheaper to build a roundabout or a tramway...}.
Finally, the neural models use a buffer which accumulates examples taken from interacting with the environment and everytime it's full they use it to learn. The examples are essentiall State-Action-Reward tuples.

The agents \textit{fixed15}, \textit{fixed30}, \textit{fixed45}, \textit{fixed60} do not learn. Instead, they follow a fixed cycle algorithm, switching phase every $k$ seconds.
Those are the baseline for comparing RL algorithms with the currently employed system. Since all agents start synchronized in the same phase, they are operated in \textit{green wave} mode.

Table \ref{tbl:agents} shows a summary of all implemented agents.

\begin{table}[H]
  \captionof{table}{Summary of implemented agents}
  \label{tbl:agents}
  \resizebox{\linewidth}{!}{
    \begin{tabular}{|l|l|l|l|l|l|l|l|l|}
      \hline
      ID      & Agent Type  & Cycle Time & Learning Algorithm           & Learning Method & Learning Policy & NN Size & Buffer Size & $\epsilon$-Greedy \\
      \hline
      fixed15 & Fixed Cycle & 15 secs    & \xmark                       & \xmark          & \xmark          & \xmark  & \xmark      & \xmark \\
      \hline
      fixed30 & Fixed Cycle & 30 secs    & \xmark                       & \xmark          & \xmark          & \xmark  & \xmark      & \xmark \\
      \hline
      fixed45 & Fixed Cycle & 45 secs    & \xmark                       & \xmark          & \xmark          & \xmark  & \xmark      & \xmark \\
      \hline
      fixed60 & Fixed Cycle & 60 secs    & \xmark                       & \xmark          & \xmark          & \xmark  & \xmark      & \xmark \\
      \hline
      sarsa   & RL Agent    & \xmark     & SARSA                        & Tabular         & On-Policy       & \xmark  & \xmark      & $\epsilon \in [0.001, 1.0] \; \; decay = 0.99$ \\
      \hline
      ql      & RL Agent    & \xmark     & Q Learning                   & Tabular         & Off-Policy      & \xmark  & \xmark      & $\epsilon \in [0.001, 1.0] \; \; decay = 0.99$ \\
      \hline
      dql     & RL Agent    & \xmark     & Double Q Learning            & Tabular         & Off-Policy      & \xmark  & \xmark      & $\epsilon \in [0.001, 1.0] \; \; decay = 0.99$ \\
      \hline
      dqn     & RL Agent    & \xmark     & Deep Q Networks              & Neural          & Off-Policy      & 32x32   & 2048        & \xmark \\
      \hline
      ppo     & RL Agent    & \xmark     & Proximal Policy Optimization & Neural          & Off-Policy      & 32x32   & 2048        & \xmark \\
      \hline
    \end{tabular}
  }
\end{table}

\section{The Tools}

This section showcases and explains the tools that have been developed as support for operating the SUMO-RL Core and carrying out simulations.
These modules include traffic generation, cross format conversions, experiments execution and run analysis.

\subsection{Importing from external sources}

\paragraph{The AMAT format}

Agenzia Mobilit\`a Ambiente Territorio (AMAT) publishes an Origin Destination matrix for the Municipality of Milan along side a graph representation of the road network infrastructure \cite{ODMilano2010}.
While the graph representation of Milan road network is too big to be used by a consumer-level commodity equipment, the format used by AMAT is interesting because it enables to reuse realistic data coming directly from mobility authorities into SUMO.
While other authorities may use different fields or tables, the DBF/SHP file formats are commonly used when dealing with labelled geographic data and with many sources like OpenStreetMap this format can be used to export data.

The road graph is composed multiple files: a SHP file for the nodes, a SHP file for graph and a DBF file for priorities and turn restrictions.
These files are essentially relational databases, which content is summarized in Tables \ref{tbl:amat-nodes-file}, \ref{tbl:amat-graph-file} and \ref{tbl:amat-turns-file}.
Note that both SHP and DBF files can be converted to SQLite3 file format which is easier to use.

The coordinates of nodes are Gauss-Boaga projections which is a map project method widely used in Italy. Those coordinates can be kept as are and mapped 1:1 to a canvas grid since they may only need scaling to adjust distances.
Usually transit simulators assume to use the metric system for unit of measures, therefore speeds and distances should be converted to m/s and m respectively.

Moreover, the AMAT format doesn't specify the number of lanes and that datum have to be inferred from \textit{Linktype} or Speed/Capacity.
Since the Milan road network uses different traffic light cycles in different zones and those are not known, the choice was to use Linktype.

Usually, in Milan and in Italy, freeways may have $4$ lanes per side, main roads may have $3$ lanes per side, secondary roads may have $2$ lanes per side and finally local roads have $1$ lane per side.
If this convention is used to infer the number of lanes, the extracted road network shows similar features to the real infrastructure, as shown in the comparison of Figures \ref{fig:gmaps-asturie-testi-la-farina} and \ref{fig:sumo-asturie-testi-la-farina}.

\begin{table}[H]
  \captionof{table}{Fields of Nodes SHP file}
  \label{tbl:amat-nodes-file}
  \resizebox{\linewidth}{!}{
    \begin{tabular}{|l|l|l|}
      \hline
      Field & Description                                                & Notes \\
      N     & Each node in the graph is identified by a unique numeric ID &       \\
      X     & Longitude coordinate in Gauss-Boaga (m) format             &       \\
      Y     & Latitude coordinate in Gauss-Boaga (m) format              &       \\
      \hline
    \end{tabular}
  }
\end{table}

\begin{table}[H]
  \captionof{table}{Fields of Graph SHP file}
  \label{tbl:amat-graph-file}
  \resizebox{\linewidth}{!}{
    \begin{tabular}{|l|l|l|}
      \hline
      Field     & Description                                                      & Notes                                                                               \\
      \hline
      ID        & Each edge in the graph is also identified by a unique numeric ID &                                                                                     \\
      \hline
      A         & Source node ID                                                   & Valid IDs are found in the Nodes file                                               \\
      \hline
      B         & Source node ID                                                   & Valid IDs are found in the Nodes file                                               \\
      \hline
      Distance  & Length of the edge from A to B                                   & Values in km                                                                        \\
      \hline
      Linktype  & Type of road edge                                                & \makecell[l]{1 = Freeway \\ 2 = Main Road \\ 3 = Secondary Road \\ 4 = Local Road}  \\
      \hline
      Speed     & Maximum allowed speed in the road edge                           & Values in km/h                                                                      \\
      \hline
      Capacity  & \makecell[l]{
                  Road capacity which is computed upon speed, number of lanes \\
                  and traffic light green-time/cycles ratio}                       & Values in number of vehicles                                                        \\
      \hline
    \end{tabular}
  }
\end{table}

\begin{table}[H]
  \captionof{table}{Fields of Turns DBF file}
  \label{tbl:amat-turns-file}
  \resizebox{\linewidth}{!}{
    \begin{tabular}{|l|l|l|}
      \hline
      Field   & Description                                                & Notes                                             \\
      \hline
      A       & Source node of the incoming edge (A-B)                     &                                                   \\
      \hline
      B       & Intersection node                                          &                                                   \\
      \hline
      C       & Sink node of the outcoming edge (B-C)                      &                                                   \\
      \hline
      Penalty & Priority is expressed as penalty in minutes $p \times 100$ & Penalty = $-1$ means that the turn is not allowed \\
      \hline
    \end{tabular}
  }
\end{table}

\putimagecouple
{\putsubimage{figures/gmaps-asturie-testi-la-farina.png}{Intersection of via Asturie, via Testi and via La Farina in Milan. Source: Google Maps}{fig:gmaps-asturie-testi-la-farina}{0.45}{1.0}}
{\putsubimage{figures/sumo-asturie-testi-la-farina.png}{A reconstruction of the intersection with the AMAT data}{fig:sumo-asturie-testi-la-farina}{0.45}{1.0}}

The Origin Destination matrix is given as multiple files representing a different time range (summarized in Table \ref{tbl:amat-time-ranges}).
Each file is in DBF format (but it can be converted to SQLite3 as before) and contains data about all vehicle transits between zones of Milan.
Those zones are enumerated in a different file alongside their borders (usually squared).
The schema of a OD file is detailed in Table \ref{tbl:amat-od-file}.

The number of vehicles specified by an entry of an OD file must be scaled with the \textit{Expansion Coefficient} which accounts for the fact that time ranges have different length.
AMAT distinguishes demand by travel reason, which in simulations may not be so useful, therefore those values are combined together to obtain the total demand.
Moreover, simulation engines like SUMO and CityFlow usually require TAZs to specify which roads to affect, therefore geographic location data from the road graph must be combined with the one for zones to build such mapping.

\begin{table}[H]
  \captionof{table}{Times ranges tracked by AMAT}
  \label{tbl:amat-time-ranges}
  \resizebox{\linewidth}{!}{
    \begin{tabular}{|c|c|l|}
      \hline
      Time Range    & Expansion Coefficient & Identified Phase \\
      \hline
      07:00 - 10:00 & 2.33                  & Morning peak     \\
      \hline
      10:00 - 16:00 & 6.00                  & Off-peak         \\
      \hline
      16:00 - 20:00 & 3.52                  & Evening peak     \\
      \hline
    \end{tabular}
  }
\end{table}

\begin{table}[H]
  \captionof{table}{Content schema of a OD file}
  \label{tbl:amat-od-file}
  \resizebox{\linewidth}{!}{
    \begin{tabular}{|l|l|l|}
      \hline
      Field     & Description                & Notes                                                                                                 \\
      \hline
      orig\_urb  & Source zone                & Valid IDs are found in the Zones file                                                                 \\
      \hline
      dest\_urb  & Sink zone                  & Valid IDs are found in the Zones file                                                                 \\
      \hline
      cd\_motivo & Reason of travel           & \makecell[l]{LAV = Work \\ AFF = Business \\ ALT = Study or other reasons \\ CAS = Returning to home} \\
      \hline
      veq\_priv  & Number of counted vehicles &                                                                                                       \\
      \hline
    \end{tabular}
  }
\end{table}

\paragraph{The CityFlow format}

\paragraph{The SUMO format}

\paragraph{The converters}

\subsection{Generating traffic}

\paragraph{flows}
\paragraph{generate-flows}
\paragraph{generate-datasets}

\subsection{Executing experiments}

\paragraph{executor}

\subsection{Extracting metrics}

\paragraph{extract-directional-metrics}
\paragraph{extract-global-metrics}

\subsection{Plotting metrics}

\paragraph{plot-global-metrics}
\paragraph{plot-smoothed-metrics}
\paragraph{plot-directional-metrics}

\subsection{Comparing metrics}

\paragraph{merge-experiments}

\paragraph{compare-global-metrics}
\paragraph{compare-directional-metrics}

\subsection{Generating reports}

\paragraph{generate-report}
