\begin{abstract}

This thesis investigates the effectiveness of curriculum learning approaches for modular training processes as alternative to monolithic (exhaustive) experience generation processes, compares tabular reinforcement learning methods to deep reinforcement learning models, evaluates the benefits of learning agents as opposed to fixed cycle traffic light programs, analyzing sensitivity of key hyperparameters such as the number of quantization levels for state space discretization, evaluates the advantages given by multi agent learning techniques, which involves sharing observations and rewards among agents, and finally determines whether a self-adaptive algorithm is able to update and correct the agent over time to make up for performances degrading over time due to demand and infrastructure changes.
A fork of the SUMO-RL framework, a bridge between SUMO (Simulator of Urban MObility) and Python which provides an integrated environment for developing and running reinforcement learning models, has been developed in order to answer the aforementioned research objectives,  enhancing its performance and capabilities, implementing new agents and observation/reward functions, allowing agents to share slices of observations/rewards and adding a self-adaptive algorithm for learning on degrading performances. Experiments are executed with the computational resources provided by hpc-ReGAInS@DISCo, which is a MUR Department of Excellence Project within the Department of Informatics, Systems and Communication at the University of Milan-Bicocca.

\end{abstract}
